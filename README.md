
# Music-to-Vector: Аудио-Векторный Анализатор

Этот инструмент предоставляет простой и рабочий метод для анализа аудиофайла и преобразования его в числовой вектор (эмбеддинг) с помощью нейросети. Вектор можно использовать для дальнейшего анализа, сравнения или, как в нашем случае, для создания творческого контента (например, сценария для видео).

Этот метод использует Google Colab и предустановленную модель **YAMNet** из библиотеки TensorFlow, что гарантирует работоспособность без необходимости в API-ключах или аутентификации.

---

## Пошаговая Инструкция

Для работы вам понадобится только аккаунт Google.

### Шаг 1: Создайте новый блокнот в Google Colab

1.  Перейдите на сайт [colab.research.google.com](https://colab.research.google.com ).
2.  В верхнем меню выберите **Файл -> Создать блокнот**. Откроется новая вкладка с пустым блокнотом.

### Шаг 2: Установка и импорт библиотек

Скопируйте весь этот код в первую ячейку вашего блокнота и запустите её, нажав на значок "Play" (▶) слева.

```python
!pip install tensorflow_hub
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import librosa
from google.colab import files
```

### Шаг 3: Загрузка вашего аудиофайла

1.  Нажмите кнопку **"+ Код"** под первой ячейкой, чтобы создать новую.
2.  Скопируйте в неё следующий код и запустите.
3.  После запуска появится кнопка **"Выберите файлы"**. Нажмите на неё и загрузите ваш аудиофайл (например, в формате `.mp3`, `.wav` и т.д.).

```python
uploaded = files.upload()
audio_file_name = list(uploaded.keys())[0]
```

### Шаг 4: Получение вектора

1.  Создайте третью, последнюю ячейку, нажав **"+ Код"**.
2.  Скопируйте в неё весь код ниже и запустите.

Этот скрипт загрузит модель YAMNet, обработает ваш аудиофайл и выведет на экран усредненный числовой вектор (эмбеддин-г), а также его размерность.

```python
# Загрузка предустановленной модели YAMNet
model = hub.load('https://tfhub.dev/google/yamnet/1' )

# Чтение и обработка вашего аудиофайла
# Модель работает с частотой дискретизации 16000 Гц
audio_data, sample_rate = librosa.load(audio_file_name, sr=16000)
scores, embeddings, spectrogram = model(audio_data)

# Усредняем вектор по всей длине аудио для получения общего "отпечатка"
final_embedding = np.mean(embeddings.numpy(), axis=0)

# Вывод результата
print("--- РЕЗУЛЬТАТ ---")
print("\nВаш усредненный вектор (аудио-эмбеддинг):")
print(final_embedding)

print("\nРазмер вектора (количество характеристик):", final_embedding.shape)
```

---

Теперь у вас есть числовое представление вашего аудиофайла, готовое для дальнейшей работы.
